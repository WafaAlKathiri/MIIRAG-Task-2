{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10710218,"sourceType":"datasetVersion","datasetId":6638003},{"sourceId":1114,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":961,"modelId":122}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q tensorflow tensorflow-hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T11:01:59.660276Z","iopub.execute_input":"2025-02-28T11:01:59.660527Z","iopub.status.idle":"2025-02-28T11:02:06.042680Z","shell.execute_reply.started":"2025-02-28T11:01:59.660504Z","shell.execute_reply":"2025-02-28T11:02:06.041107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\n\nmodule_path =\"/kaggle/input/bigbigan/tensorflow1/resnet50/1\"\n\n# Load the BigBiGAN model from TensorFlow Hub\nbigbigan = hub.load(module_path) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T11:03:43.690793Z","iopub.execute_input":"2025-02-28T11:03:43.691219Z","iopub.status.idle":"2025-02-28T11:04:26.036164Z","shell.execute_reply.started":"2025-02-28T11:03:43.691184Z","shell.execute_reply":"2025-02-28T11:04:26.035058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Printing signatures to understand model strcuture \nprint(bigbigan.signatures)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T11:04:29.298592Z","iopub.execute_input":"2025-02-28T11:04:29.298980Z","iopub.status.idle":"2025-02-28T11:04:29.305544Z","shell.execute_reply.started":"2025-02-28T11:04:29.298952Z","shell.execute_reply":"2025-02-28T11:04:29.304204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Define dataset path\ndataset_path = \"/kaggle/input/cleandata/Road_Crack_Dataset_Cleaned_labled\"\n\n# Function to load images without labels\ndef load_images_from_directory(directory, batch_size=32):\n    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n        directory,\n        image_size=(128, 128),  # Resize to match BigBiGAN input\n        batch_size=None,\n        label_mode=None  # Ignore labels, only load images\n    )\n    return dataset\n\n# Load datasets\ntrain_dataset = load_images_from_directory(dataset_path + \"/train/class_4\")\nval_dataset = load_images_from_directory(dataset_path + \"/valid/class_4\")\ntest_dataset = load_images_from_directory(dataset_path + \"/test/class_4\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T11:04:32.284774Z","iopub.execute_input":"2025-02-28T11:04:32.285183Z","iopub.status.idle":"2025-02-28T11:04:32.637430Z","shell.execute_reply.started":"2025-02-28T11:04:32.285152Z","shell.execute_reply":"2025-02-28T11:04:32.636226Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pathlib\n\n# check images have been loaded properly \nsubfolders = list(pathlib.Path(dataset_path + \"/train\").glob(\"*\"))\nprint(\"Subfolders detected:\", [folder.name for folder in subfolders])\n\n# List some image files\nimage_files = list(pathlib.Path(dataset_path + \"/train/class_0\").glob(\"*.png\"))[:5]\nprint(\"Sample images from class_0:\", [img.name for img in image_files])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T11:04:37.730530Z","iopub.execute_input":"2025-02-28T11:04:37.730944Z","iopub.status.idle":"2025-02-28T11:04:37.742726Z","shell.execute_reply.started":"2025-02-28T11:04:37.730884Z","shell.execute_reply":"2025-02-28T11:04:37.741776Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\ndef preprocess(image):\n    # Ensure the image has 3 channels (RGB) if it's grayscale\n    if len(image.shape) == 3 and image.shape[-1] == 1:  # Grayscale image (1 channel)\n        image = tf.image.grayscale_to_rgb(image)  # Convert to RGB\n\n    # Resize the image to 128x128\n    image = tf.image.resize(image, [128, 128])\n    \n    # Normalize pixel values\n    image = image / 255.0\n\n    # Add the batch dimension, making it [1, 128, 128, 3]\n    image = tf.expand_dims(image, axis=0)\n    \n    return image\n\n# Apply preprocessing to the datasets\ntrain_dataset = train_dataset.map(lambda x: preprocess(x)) \\\n    .shuffle(1000) \\\n    .batch(32, drop_remainder=True) \\\n    .prefetch(tf.data.AUTOTUNE)\n\nval_dataset = val_dataset.map(lambda x: preprocess(x)) \\\n    .batch(32) \\\n    .prefetch(tf.data.AUTOTUNE)\n\ntest_dataset = test_dataset.map(lambda x: preprocess(x)) \\\n    .batch(32) \\\n    .prefetch(tf.data.AUTOTUNE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T11:04:40.305632Z","iopub.execute_input":"2025-02-28T11:04:40.306026Z","iopub.status.idle":"2025-02-28T11:04:40.478844Z","shell.execute_reply.started":"2025-02-28T11:04:40.305995Z","shell.execute_reply":"2025-02-28T11:04:40.477545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract generator & encoder\ngenerator = bigbigan.signatures['generate']\nencoder = bigbigan.signatures['encode']\n\n# Define optimizer & loss function\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\nloss_fn = tf.keras.losses.MeanSquaredError()\n\n# Fine-tune the generator\n# Modify the training loop to ensure the inputs are correctly formatted\n\ndef train_generator(epochs=10):\n    for epoch in range(epochs):\n        epoch_loss = 0\n        for image_batch in train_dataset:\n            with tf.GradientTape() as tape:\n                # Squeeze the extra dimensions if they exist\n                image_batch = tf.squeeze(image_batch, axis=1)  # Remove any singleton dimensions\n                \n                # Ensure the shape is [batch_size, 128, 128, 3]\n                image_batch = tf.ensure_shape(image_batch, [None, 128, 128, 3])\n\n                # Encode images to latent space\n                z = encoder(image_batch)['default']\n                reconstructed = generator(z)['default']  # Generate images\n                loss = loss_fn(image_batch, reconstructed)  # Compute reconstruction loss\n\n            gradients = tape.gradient(loss, generator.trainable_variables)\n            optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n\n            epoch_loss += loss.numpy()\n\n        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss / len(train_dataset)}')\n\ntrain_generator(epochs=10)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T11:04:55.515776Z","iopub.execute_input":"2025-02-28T11:04:55.516214Z","iopub.status.idle":"2025-02-28T12:18:12.982079Z","shell.execute_reply.started":"2025-02-28T11:04:55.516181Z","shell.execute_reply":"2025-02-28T12:18:12.979002Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:47:16.975332Z","iopub.execute_input":"2025-02-27T22:47:16.975695Z","iopub.status.idle":"2025-02-27T22:47:16.984627Z","shell.execute_reply.started":"2025-02-27T22:47:16.975669Z","shell.execute_reply":"2025-02-27T22:47:16.983635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Unwrap the tf.function by getting the concrete function\nconcrete_function = generator.__call__.get_concrete_function()\ntf.saved_model.save(concrete_function, '/kaggle/working/fine_tuned_generator')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:46:58.652102Z","iopub.execute_input":"2025-02-27T22:46:58.652634Z","iopub.status.idle":"2025-02-27T22:46:58.681498Z","shell.execute_reply.started":"2025-02-27T22:46:58.652595Z","shell.execute_reply":"2025-02-27T22:46:58.680015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the entire model\ngenerator.save('/kaggle/working/fine_tuned_generator')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:45:21.731255Z","iopub.execute_input":"2025-02-27T22:45:21.731767Z","iopub.status.idle":"2025-02-27T22:45:21.858129Z","shell.execute_reply.started":"2025-02-27T22:45:21.731719Z","shell.execute_reply":"2025-02-27T22:45:21.856605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generator_model.save('/kaggle/working/fine_tuned_generator')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:48:47.678719Z","iopub.execute_input":"2025-02-27T22:48:47.679190Z","iopub.status.idle":"2025-02-27T22:48:47.704842Z","shell.execute_reply.started":"2025-02-27T22:48:47.679160Z","shell.execute_reply":"2025-02-27T22:48:47.703335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tf.saved_model.save(generator, '/kaggle/working/fine_tuned_generator')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:51:02.603207Z","iopub.execute_input":"2025-02-27T22:51:02.603632Z","iopub.status.idle":"2025-02-27T22:51:02.866019Z","shell.execute_reply.started":"2025-02-27T22:51:02.603604Z","shell.execute_reply":"2025-02-27T22:51:02.864564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"generator.load_weights('/kaggle/working/fine_tuned_generator_weights.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T22:51:36.661132Z","iopub.execute_input":"2025-02-27T22:51:36.661554Z","iopub.status.idle":"2025-02-27T22:51:36.686989Z","shell.execute_reply.started":"2025-02-27T22:51:36.661524Z","shell.execute_reply":"2025-02-27T22:51:36.685462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a checkpoint object\ncheckpoint = tf.train.Checkpoint(generator=generator)\n\n# Save the weights\ncheckpoint.save('/kaggle/working/fine_tuned_generator_ckpt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T12:18:48.974782Z","iopub.execute_input":"2025-02-28T12:18:48.975319Z","iopub.status.idle":"2025-02-28T12:18:49.032530Z","shell.execute_reply.started":"2025-02-28T12:18:48.975285Z","shell.execute_reply":"2025-02-28T12:18:49.031326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract generator & encoder\ngenerator = bigbigan.signatures['generate']\nencoder = bigbigan.signatures['encode']\n\n# Define optimizer & loss function\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\nloss_fn = tf.keras.losses.MeanSquaredError()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the checkpoint directory and base name\ncheckpoint_dir = '/kaggle/working'\ncheckpoint_prefix = f\"{checkpoint_dir}/fine_tuned_generator_ckpt\"\n\n# Create a checkpoint object\ncheckpoint = tf.train.Checkpoint(generator=generator, optimizer=optimizer)\n\n# Restore from the specific checkpoint if it exists\ncheckpoint_path = f\"{checkpoint_prefix}-1\"  # Use the base name without the file extensions\ncheckpoint.restore(checkpoint_path).expect_partial()\nprint(f\"Restored from checkpoint: {checkpoint_path}\")\n\n# Continue fine-tuning\ndef train_generator(epochs=10):\n    for epoch in range(epochs):\n        epoch_loss = 0\n        for image_batch in train_dataset:\n            with tf.GradientTape() as tape:\n                # Squeeze the extra dimensions if they exist\n                image_batch = tf.squeeze(image_batch, axis=1)  # Remove any singleton dimensions\n                \n                # Ensure the shape is [batch_size, 128, 128, 3]\n                image_batch = tf.ensure_shape(image_batch, [None, 128, 128, 3])\n\n                # Encode images to latent space\n                z = encoder(image_batch)['default']\n                reconstructed = generator(z)['default']  # Generate images\n                loss = loss_fn(image_batch, reconstructed)  # Compute reconstruction loss\n\n            gradients = tape.gradient(loss, generator.trainable_variables)\n            optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n\n            epoch_loss += loss.numpy()\n\n        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss / len(train_dataset)}')\n\n        # Save checkpoint after each epoch\n        checkpoint.save(file_prefix=checkpoint_prefix)\n        print(f\"Checkpoint saved at {checkpoint_prefix}\")\n\ntrain_generator(epochs=10)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T12:19:21.617668Z","iopub.execute_input":"2025-02-28T12:19:21.618172Z","iopub.status.idle":"2025-02-28T13:05:40.403725Z","shell.execute_reply.started":"2025-02-28T12:19:21.618142Z","shell.execute_reply":"2025-02-28T13:05:40.400200Z"}},"outputs":[],"execution_count":null}]}